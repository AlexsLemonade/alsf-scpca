---
title: "SCRNAseq quantification comparisons: Data Import"
author: "Joshua Shapiro for CCDL"
output: 
  html_notebook:
    toc: true
    toc_float: true
---

This notebook contains code to import and do preliminary processing single cell expression data, quantified by Alevin, Alevin-fry, Kallisto, and Cellranger. 
Alevin samples were quantified with and without decoy sequences.
Alevin-fry samples were quantified with and without `--sketch` mode and with and without `--unfiltered` mode to allow for the permitted 10x barcode list. 
The imported data is stored as SingleCellExperiment objects, which are then saved as an `.rds` file for later analysis.

## Setup

### Load Libraries for import

```{r setup}
library(magrittr)
library(SingleCellExperiment)
library(DropletUtils)
library(tximport)
library(Matrix.utils)
```

### File and directory setup

Input file locations first, local and remote (S3)

```{r}
base_dir <- here::here()

data_dir <- file.path(base_dir, 'data', 'quants')
dir.create(data_dir, recursive = TRUE, showWarnings = FALSE)

alevin_data_dir <- file.path(data_dir, 'alevin')
dir.create(alevin_data_dir, recursive = TRUE, showWarnings = FALSE)
quant_s3_alevin <- 's3://nextflow-ccdl-results/scpca/alevin-quant'

alevin_fry_data_dir <- file.path(data_dir, 'alevin-fry')
dir.create(alevin_fry_data_dir, recursive = TRUE, showWarnings = FALSE)
quant_s3_alevin_fry <- 's3://nextflow-ccdl-results/scpca/alevin-fry-quant'

kallisto_data_dir <- file.path(data_dir, 'kallisto')
dir.create(kallisto_data_dir, recursive = TRUE, showWarnings = FALSE)
quant_s3_kallisto <- 's3://nextflow-ccdl-results/scpca/kallisto-quant'

cellranger_data_dir <- file.path(data_dir, 'cellranger')
dir.create(cellranger_data_dir, recursive = TRUE, showWarnings = FALSE)
quant_s3_cellranger <- 's3://nextflow-ccdl-results/scpca/cellranger-quant'
```

Output files will be a TSV format info file and `.rds` files of the SingleCellExperiment objects, stored in a subdirectory of this notebook's location.

```{r}
export_dir <- 'data'
if (!dir.exists(export_dir)){
  dir.create(export_dir)
}

quant_info_file <- file.path(export_dir, 'quant_info.tsv')

alevin_rds <- file.path(export_dir, 'alevin_sces.rds')
alevin_fry_rds <- file.path(export_dir, 'alevin_fry_sces.rds')
alevin_fry_sketch_rds <- file.path(export_dir, 'alevin_fry_sketch_sces.rds')
alevin_fry_unfiltered_rds <- file.path(export_dir, 'alevin_fry_unfiltered_sces.rds')
alevin_fry_unfiltered_sketch_rds <- file.path(export_dir, 'alevin_fry_unfiltered_sketch_sces.rds')
kallisto_rds <- file.path(export_dir, 'kallisto_sces.rds')
cellranger_rds <- file.path(export_dir, 'cellranger_sces.rds')

```



### Sync S3 files

```{r}
samples <- c('SCPCR000003', 'SCPCR000006', 'SCPCR000118', 'SCPCR000119', 'SCPCR000126', 'SCPCR000127')

# generate include statements for sample directories
includes <- stringr::str_glue("--include \"*/{samples}*\"")

# Alevin quantification files
sync_call <- paste('aws s3 sync', quant_s3_alevin, alevin_data_dir, 
                   includes)
system(sync_call, ignore.stdout = TRUE)

# Alevin fry quantification files 
sync_call <- paste('aws s3 sync', quant_s3_alevin_fry, alevin_fry_data_dir,
                   includes, '--exclude "*.rad"')
system(sync_call, ignore.stdout = TRUE)

# Kallisto quantification files
# exclude bus files, which are large
sync_call <- paste('aws s3 sync', quant_s3_kallisto, kallisto_data_dir,
                   includes, '--exclude "*/bus/*"')
system(sync_call, ignore.stdout = TRUE)

# Cell Ranger quantification files
# exclude intermediate and bam files
sync_call <- paste('aws s3 sync', quant_s3_cellranger, cellranger_data_dir,
                   includes, 
                   '--exclude "*/SC_RNA_COUNTER_CS/*"',
                   '--exclude "*.bam"', '--exclude "*.bam.bai"')
system(sync_call, ignore.stdout = TRUE)
```


### Generate sample info data frame

This generates the sample list from the directory names of the downloads. 

```{r}
quant_info <- c(alevin = alevin_data_dir, 
                alevin_fry = alevin_fry_data_dir,
                kallisto = kallisto_data_dir,
                cellranger = cellranger_data_dir) %>%
  purrr::map(list.dirs, recursive = FALSE, full.names = FALSE) %>%
  # convert to data frame
  tibble::enframe(name = "tool", value = "quant_dir") %>%
  tidyr::unnest(quant_dir) %>%
  # parse the `quant_dir` into sample and index info
  tidyr::separate(quant_dir, 
                  sep = "[-]",
                  into = c("sample", "index_type", "alevin_alignment", "alevin_permit_list"),
                  remove = FALSE) %>%
  tidyr::separate(index_type, 
                  into = c("index_type", "kmer"), 
                  extra = "drop",
                  fill = "right",
                  sep = "txome_") %>%
  tidyr::separate(kmer, 
                  into = c("kmer", "decoy"),
                  extra = "drop", 
                  fill = "right") %>%
  dplyr::filter(sample %in% samples) %>%
  # no decoy samples get NA here, convert to text.
  dplyr::mutate(decoy = tidyr::replace_na(decoy, "no")) %>%
  dplyr::mutate(index_type = ifelse(index_type == "", "txome", index_type)) %>%
  dplyr::mutate(alevin_alignment = tidyr::replace_na(alevin_alignment, "not_alevin")) %>%
  dplyr::mutate(alevin_permit_list = tidyr::replace_na(alevin_permit_list, "not_alevin"))
```

```{r}
# collapse by index type so that everything is either labeled as cDNA or pre-mRNA
quant_info <- quant_info %>% 
  # remove 119 run with txome from analysis
  dplyr::filter(quant_dir != "SCPCR000119-txome_k31") %>%
  dplyr::mutate(index_type = ifelse(
    index_type %in% c("cdnapre_mRNA", "spliced_intron_"), "pre-mRNA", "cDNA"))
```



```{r}
# add in library metadata for each sample  
library_data_dir <- file.path(base_dir, 'sample-info')
dir.create(library_data_dir, recursive = TRUE, showWarnings = FALSE)
sample_info_dir_s3 <- 's3://ccdl-scpca-data/sample_info'

# grab library metadata from location in s3
sync_call <- paste('aws s3 sync', sample_info_dir_s3, library_data_dir,
                   '--exclude "*"', 
                   '--include "*scpca-library-metadata.tsv"')
system(sync_call, ignore.stdout = TRUE)
```

```{r}
# read in sample metadata
library_df <- readr::read_tsv(file.path(library_data_dir, "scpca-library-metadata.tsv"))
```

```{r}
# filter data frame with information that might be relevant for looking at these samples
select_metadata_df <- library_df %>%
  dplyr::select(scpca_run_id, scpca_sample_id, seq_unit, technology)
```

```{r}
# add relevant metadata to quant information table
quant_info <- quant_info %>%
  dplyr::inner_join(select_metadata_df, by = c("sample" = "scpca_run_id" ))
# save info table
readr::write_tsv(quant_info, quant_info_file )
# print the info table
quant_info
```

```{r}
annotation_data_dir <- file.path(base_dir, 'annotation')
dir.create(annotation_data_dir, recursive = TRUE, showWarnings = FALSE)
annotation_data_dir_s3 <- 's3://nextflow-ccdl-data/reference/homo_sapiens/ensembl-103/annotation'

# grab spliced_intron metadata table
sync_call <- paste('aws s3 sync', annotation_data_dir_s3, annotation_data_dir,
                   '--exclude "*"', 
                   '--include "*Homo_sapiens.GRCh38.103.spliced_intron.metadata.tsv"')
system(sync_call, ignore.stdout = TRUE)
```

```{r}
intron_metadata <- readr::read_tsv(
  file.path(annotation_data_dir, "Homo_sapiens.GRCh38.103.spliced_intron.metadata.tsv")
  ) %>%
  # move intron column to rownames to use for collapsing counts matrix later
  tibble::column_to_rownames("intron")

head(intron_metadata)
```

## Process quantification files

To process the alevin, alevin-fry and kallisto quantification files, we need to import the counts matrices, subset the counts matrices for the snRNA-seq samples to make a collapsed counts matrix, and then convert to a single cell experiment. 

Since we are going to be doing this quite a few times, we can write a function to do that. 
I also have two separate functions, one to collapse intron counts, and one to specifically read in kallisto .mtx files that are going to be used within the larger import function that we want to fun first. 

```{r}
# for every combination of mrna + intronic region create a collapsed counts matrix that contains the sum of the total counts for that gene (mrna + intron)
# we could use tximeta::splitSE but it just creates two separate matrices rather than one combined one 
collapse_intron_counts <- function(counts, intron_metadata) {
  # find the shared genes in that counts matrix 
  shared_genes <- intersect(row.names(counts), rownames(intron_metadata))
  # replace row names with -I appended with corresponding spliced gene 
  row.names(counts)[which(row.names(counts) %in% shared_genes)] <- intron_metadata[shared_genes, "spliced"]
  # aggregate Matrix counts by gene name 
  aggregate.Matrix(counts, row.names(counts))
}
```

```{r}
read_kallisto_counts <- function(base) {
  counts <- Matrix::readMM(paste0(base,".mtx"))%>%
    t() %>% # transpose to gene x cell orientation
    as("dgCMatrix") # compress sparse matrix
  dimnames(counts) <- list(readLines(paste0(base,".", "genes.txt")),
                           readLines(paste0(base,".barcodes.txt")))
  return(counts)
}
```


```{r}
import_quant_data <- function(quant_ids, tool = tool, data_dir, intron_metadata) {
  # if tool is kallisto, then read in using the read_kallisto_counts
  if(tool == "kallisto") {
    base_file <- file.path(data_dir, quant_ids, "counts", "gene_count")
    counts_list <- base_file %>%
      purrr::map(read_kallisto_counts)
  # otherwise read in directly using tximport
  # we are only using this for alevin or kallisto based tools, so I did hardcode it for alevin in tximport
  } else {
    counts_list <- quant_ids %>%
      purrr::map(
        ~ tximport(file.path(data_dir, .x, "alevin", "quants_mat.gz"),
               type = "alevin")) %>%
      purrr::map(~ SingleCellExperiment(list(counts = .x$counts))) %>%
      purrr::map(counts)
  }
  # once we have a list of counts matrices we want to take any that were aligned to the spliced_intron index and collapse the counts
  names(counts_list) <- quant_ids
  counts_list_nuclei <- counts_list[grep("spliced_intron", names(counts_list))] %>%
    purrr::map(
      ~ collapse_intron_counts(.x, intron_metadata)
      )

  # replace the sces in the original list with the collapsed sces
  counts_list[names(counts_list_nuclei)] <- counts_list_nuclei

  # convert counts list to sces and return 
  sces <- counts_list %>%
    purrr::map(~ SingleCellExperiment(list(counts = .x)))
  return(sces)
    
}

```


### Alevin

```{r}
# for each alevin configuration we need to get the quant ids that will be input to import_quant_data
alevin_quant_ids <- quant_info %>%
  dplyr::filter(tool == "alevin") %>%
  dplyr::pull(quant_dir)

alevin_sces <- import_quant_data(quant_ids = alevin_quant_ids, 
                                 tool = "alevin",
                                 data_dir = alevin_data_dir, 
                                 intron_metadata = intron_metadata)
```



```{r}
## alevin fry, no permit list, no sketch 
alevin_fry_quant_ids <- quant_info %>%
  dplyr::filter(tool == "alevin_fry" & alevin_permit_list != "unfiltered" & alevin_alignment == "salign") %>%
  dplyr::pull(quant_dir)

alevin_fry_sces <- import_quant_data(quant_ids = alevin_fry_quant_ids, 
                                 tool = "alevin_fry",
                                 data_dir = alevin_fry_data_dir, 
                                 intron_metadata = intron_metadata)
```



```{r}
## alevin fry, no permit list, with sketch 
alevin_fry_sketch_quant_ids <- quant_info %>%
  dplyr::filter(tool == "alevin_fry" & alevin_permit_list != "unfiltered" & alevin_alignment == "sketch") %>%
  dplyr::pull(quant_dir)

alevin_fry_sketch_sces <- import_quant_data(quant_ids = alevin_fry_sketch_quant_ids, 
                                 tool = "alevin_fry",
                                 data_dir = alevin_fry_data_dir, 
                                 intron_metadata = intron_metadata)
```


When we read in the counts data that has been processed with alevin-fry using the --unfiltered flag rather than using --knee-distance, all cells that are identified in the 10X whitelist are output. 
This means that we are going to have cells that are not considered 'true' cells and we need to filter them out before doing any comparisons across the tools. 
We could use `DropletUtils::barcodeRanks` but even after using that we still see some samples with 50,000 cells above the knee. 
According to the documenation for DropletUtils another recommendation is to use their method for detecting [empty droplets](https://www.bioconductor.org/packages/devel/bioc/vignettes/DropletUtils/inst/doc/DropletUtils.html#detecting-empty-droplets). 
Here, I am implementing `DropletUtils::emptyDrops` for the alevin-fry samples used with the `--unfiltered` flag. 

According to the documentation, `DropletUtils::emptyDrops` tests for empty drops in the following way: 
> The emptyDrops function is designed to distinguish between empty droplets and cells. It does so by testing each barcodeâ€™s expression profile for significant deviation from the ambient profile.
> Droplets with significant deviations from the ambient profile are detected at a specified FDR threshold, e.g., with FDR below 1%. These can be considered to be cell-containing droplets, with a frequency of false positives (i.e., empty droplets) at the specified FDR. Furthermore, droplets with very large counts are automatically retained by setting their p-values to zero. This avoids discarding droplets containing cells that are very similar to the ambient profile.
> The p-values are calculated by permutation testing, hence the need to set a seed. The Limited field indicates whether a lower p-value could be obtained by increasing the number of permutations. If there are any entries with FDR above the desired threshold and Limited==TRUE, it indicates that npts should be increased in the emptyDrops call.

```{r}
filter_counts_mtx <- function(sce){
    # grab counts from single cell experiment
    counts <- counts(sce)
    # calculate probability of being an empty droplet
    empty_df <- DropletUtils::emptyDrops(counts)
    cells <- rownames(empty_df[which(empty_df$Limited == "TRUE" & empty_df$FDR <= 0.01),])
    # subset original counts matrix by cells that pass filter
    counts <- counts[, cells]
    return(counts)
}
```


```{r}
## alevin fry, permit list, no sketch 
alevin_fry_unfiltered_quant_ids <- quant_info %>%
  dplyr::filter(tool == "alevin_fry" & alevin_permit_list == "unfiltered" & alevin_alignment == "salign") %>%
  dplyr::pull(quant_dir)

alevin_fry_unfiltered_sces <- import_quant_data(quant_ids = alevin_fry_unfiltered_quant_ids, 
                                 tool = "alevin_fry",
                                 data_dir = alevin_fry_data_dir, 
                                 intron_metadata = intron_metadata)

## for now remove alevin_fry_unfiltered_nucleus_sces because they are empty runs and giving empty matrices... 
nucleus_ids <- grep("spliced_intron", names(alevin_fry_unfiltered_sces))
alevin_fry_unfiltered_sces <- alevin_fry_unfiltered_sces[-nucleus_ids]
```


```{r}
# cell filtering 
alevin_fry_unfiltered_sces <- alevin_fry_unfiltered_sces %>% 
  purrr::map(
    ~ filter_counts_mtx(.x)) %>%
  purrr::map(
    ~ SingleCellExperiment(list(counts = .x)))

alevin_fry_unfiltered_sces
```


```{r}
## alevin fry, permit list, with sketch 
alevin_fry_unfiltered_sketch_quant_ids <- quant_info %>%
  dplyr::filter(tool == "alevin_fry" & alevin_permit_list == "unfiltered" & alevin_alignment == "sketch") %>%
  dplyr::pull(quant_dir)

alevin_fry_unfiltered_sketch_sces <- import_quant_data(quant_ids = alevin_fry_unfiltered_sketch_quant_ids, 
                                 tool = "alevin_fry",
                                 data_dir = alevin_fry_data_dir, 
                                 intron_metadata = intron_metadata)
```


```{r}
# cell filtering 
alevin_fry_unfiltered_sketch_sces <- alevin_fry_unfiltered_sketch_sces %>% 
  purrr::map(
    ~ filter_counts_mtx(.x)) %>%
  purrr::map(
    ~ SingleCellExperiment(list(counts = .x)))
```


### Kallisto

Process Kallisto files in a similar way to Alevin --unfiltered by importing the .mtx file as a sparse matrix, collapsing the intron counts, and then performing cell filtering using `DropletUtils::emptyDrops`

```{r}
kallisto_quant_ids <- quant_info %>%
  dplyr::filter(tool == "kallisto") %>%
  dplyr::pull(quant_dir)

kallisto_sces <- import_quant_data(quant_ids = kallisto_quant_ids, 
                                 tool = "kallisto",
                                 data_dir = kallisto_data_dir, 
                                 intron_metadata = intron_metadata) %>%
  purrr::map(
    ~ filter_counts_mtx(.x)) %>%
  purrr::map(
    ~ SingleCellExperiment(list(counts = .x)))
```


### Cellranger

Use `DropletUtils::read10xCounts()` to read cellranger counts as SCEs

```{r}
cellranger_quant_ids <- quant_info %>%
  dplyr::filter(tool == "cellranger") %>%
  dplyr::pull(quant_dir)

cellranger_sces <- cellranger_quant_ids  %>%
  purrr::map(
    ~ read10xCounts(file.path(cellranger_data_dir, .x,
                              "outs", "filtered_feature_bc_matrix.h5"),
                    sample.names = .x,
                    col.names = TRUE)
  ) %>% 
  purrr::map(
    # for consistency with other quantifiers:
    # change the column names just the barcode value, which is the first part of the barcode name
    # drop colData
    function(x) {
      colnames(x) <- stringr::str_extract(colnames(x), "^([ACGT]+)")
      colData(x) <- NULL
      return(x)
    }
  )

# add names
names(cellranger_sces) <- cellranger_quant_ids
```

## Export SingleCellExperiment objects

```{r}
readr::write_rds(alevin_sces, alevin_rds)
readr::write_rds(alevin_fry_sces, alevin_fry_rds)
readr::write_rds(alevin_fry_sketch_sces, alevin_fry_sketch_rds)
readr::write_rds(alevin_fry_unfiltered_sces, alevin_fry_unfiltered_rds)
readr::write_rds(alevin_fry_unfiltered_sketch_sces, alevin_fry_unfiltered_sketch_rds)
readr::write_rds(kallisto_sces, kallisto_rds)
readr::write_rds(cellranger_sces, cellranger_rds)
```

## Session info

```{r paged.print=FALSE}
sessioninfo::session_info()
```
